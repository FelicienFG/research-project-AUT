
\section{Related Works}
\label{sec:literature}

\subsection{Systematic Literature Review process}

\paraheading{\textbf{Scoping}}

This SLR aims at tackling RQ1. More precisely, the following research questions will be answered:

\begin{itemize}
    \item [RQ1.1] What is the current state-of-the-Art for DAG task scheduling with precedence constraints ?
    \item [RQ1.2] How has LET been used in scheduling event-chains ?
\end{itemize}
It will also be shown how the literature doesn't provide 
a complete answer to RQ2, hence the contributions of this paper.\\

From these research questions, several concepts have been isolated,
namely, time-triggered tasks, the nature of the system (real-time multicore system),
the scheduling of tasks, DAG tasks, and machine learning.
The recording of the search results were done using the BibTeX LateX plugin
combine with the google scholar "cite" feature.

Searching was conducted using the IEEE and ACM databases.
According to the concepts identified above, 
the keyword chain used for searching was 
"("real-time" OR "real time") AND 
"system" AND ("time-triggered" OR "time triggered" OR "DAG" OR "Directed Acyclic Graph" OR "LET" OR "Logical Execution Time" OR "event chain" OR "event-chain") 
AND "task" 
AND ("scheduling" OR "scheduler" OR "schedule") 
AND ("multi-processors" OR "multi-cores" OR "multi processors" OR 
"multi cores" OR "multi-processor" OR "multi processor" OR 
"multi-core" OR "multi core")".

The search produced 3,549 results on the IEEE database

exclusion : past 5 years : IEEE --> down to 1,171 
            heterogeneous not in title + abstract : IEEE --> down to 999
            mixed critical* not in title + abstract : IEEE --> down to 952
            scheduling or scheduler or schedule in title but not "energy" :  IEEE --> down to 155 and 149 when just considering conference and journal papers (not early access)
            
            removing those not about real-time system,
            not about proposing a scheduling algorithm,
            not about DAG nor LET tasks or event-chains : IEEE --> down to 21

\paragraph{}

\subsection{Findings of the Literature Review}

\paraheading{The works reviewed were compared on the following metrics.} 
\begin{itemize}
    \item \textbf{Utilization Bound}: useful to see which algorithm is more efficient at using the available resources.
    \item \textbf{Acceptance Ratio}: it shows how optimal (see Section \ref{sec:bg}) a scheduling algorithm is.
    \item \textbf{Makespan}: for DAG task scheduling, widely used in the literature.
    \item \textbf{Runtime Overhead}: some scheduling algorithms can show promising results theoretically but are practically very slow because 
    of their complexity adding runtime overhead on the scheduler, this metric will not be a number but rather an amount such as minimal, practical, non-practical.
\end{itemize}
Every metric used here have also been chosen for their prevalence in the literature.

A comparison of the works was carried out and the overall results are illustrated in Table~\ref{tab:slrtable}.
 

\begin{table}
    \centering
    \begin{tabular}[]{|l|p{0.20\linewidth}|p{0.20\linewidth}|p{0.20\linewidth}|p{0.20\linewidth}|}
        \hline
        \textbf{Reference} & \textbf{Motivation} & \textbf{Contribution(s)} & \textbf{Limitation(s)} & \textbf{Methodology Summary}\\
        \hline
        \cite{guan2021DAGfluid}  & DAG tasks scheduling is getting more popular and fluid scheduling performs great theoretically & Provide a DAG-fluid scheduling algorithm
        that performs way better in terms of acceptance ratio then previous algorithms & Fluid scheduling is unpractical and introduces a lot of overhead and task migrations, also only for implicit deadlines tasks
        & fluid-based algorithm where it decomposes a DAG's subtasks into multiple sequential segments\\
        \hline
        \cite{He2019DagIntra}  & DAGs are popular but no one looked at the intra-task execution order to leverage the graph structure & proposes a priority list scheduling algorithm for a single DAG task
        which performs better than SOTA in terms of makespan & no comparison with optimal priority assignment algorithms / optimal schedules.  & uses the length (in terms of wcets) of each paths passing through the current vertex to assign the priority to the current vertex,
        the higher the length, the higher priority \\
        \hline
        \cite{Kobayashi2023FedBundledDagsched} & Federated scheduling for DAG tasks is has proved efficient but 
        for tasks where the difference between the critical path and the deadline is small, it
        can lead to over-allocating cores.  & proposed a fedrated and bundled-based scheduling algorithm to avoid this problem and enhanced the schedulability of DAG tasks using their algorithms & They only compare their method with an example of a dag task set comprised of 3 dag tasks. & Uses federated scheduling for tasks with high critical path to deadline ratio and bundled scheduling for tasks with low critical path to deadline ratio. \\
        \hline
        \cite{Xiao2019} & DAG task scheduling is NP-hard so one can only approximate the optimal algorithm (when considering polynomial timed algorithms)
        and not a lot has been done on scheduling parrallel reccuring tasks & Introduces a scheduling algorithm 'MAS' that shortens the makespan of recurring DAG tasks compared to EDF & only compares EDF and MAS using one example of a DAG task for makespans and also only compares with EDF.
        Even though MAS shortens the makespan, it is less scalable than comparable algorithms. & The MAS algorithm combines techniques from clustering scheduling and task duplication algorithm and evaluates it on an actual simulation object (the TMS320C6678) so that the measurement are close to the real-life measurement you would get on the real system.\\
        \hline
        \cite{Igarashi2020HeuristicContentionFree}  & The use of multi-core systems can induce contentions because of shared memory / cache. This can lead to non-determinim and unpredictable behavior which
        violates the safety requirements of real-time systems, hence using LET tasks to fix those contentions 
        but LET also suffers from additional execution time being added because of the implementation overhead.
        & Proposes a DAG LET tasks scheduling algorithm based that avoids contentions while reducing the running time overhead
        due to LET implementation & They are using a multiple-clusters, multi-core architecture to evaluate their scheduling algorithm
        but only consider one cluster. & Uses a minimum-laxity-first priority assignment for intra-tasks and Earliest Finish time (EFT) for assigning tasks to cores.
        Considers multi-rate dags and reducing the LET interval to decrease the makespan. \\
        \hline
        \cite{jiangUtilTensityBound}  & The capacity-bound is a bound used as a performance measurement 
        but also as a schedulability test for DAG scheduling. However, 
        it uses the same bound to bound both the normalized utilization and the tensity (critical path over the deadline) of a DAG task which 
        can exclude DAG tasks that actually are schedulable but not according to this capacity-bound. & Introduces a new bound called the util-tensity bound
        which proves to be a better schedulability test for GEDF with federated scheduling. & 
        only looks at GEDF with federated scheduling and not other scheduling algorithms. & 
        The scheduling algorithm applied uses GEDF for very low tensity tasks,
        tasks with high utilization and relatively high tensities are scheduled using federated scheduling,
        and low utilization tasks with relatively high tensities are scheduled by partitioned EDF\\
        \hline
        \cite{JiangDecompoSchedParallelTask}  & Decomposition-based scheduling can improve schedulability
        for DAG task scheduling but can also worsen it.
        It is, along with global scheduling, one of the main
        method to schedule DAG tasks. & Develop a decomposition strategy
        as well as a metric / schedulability test 
        and the decomposition strategy proves to be the most efficient one
        according to the defined metric. The scheduling algorithm
        derived from this decomposition strategy (using GEDF variants) shows promising
        results in terms of acceptance ratios & Only looks at GEDF variants which is based on the EDF heuristics for priority assignments.& The decomposition works by first defining execution segments
        and then assigning subtasks to those segments based on their laxity so that there are no segments overloaded with workload. \\
        \hline
        \cite{He2023DegreeOfParallelism} & The notion of degree of parallelism has been used 
        for DAG task scheduling but lacks a clear definition in the research community. & Proposes a new response-time bound for DAG tasks
        as well as a new scheduling algorithm based on federated scheduling that outperforms the SOTA
        by more than 18\% on average & They don't say which intra-task scheduling algorithm is used (just that it's work-conserving)
        and they don't consider intra-task scheduling. & Using the defined notion of degree of parallelism,
        they modify the federated scheduling approach by having a better way of choosing
        the number of cores for heavy tasks, which is based on the degree of parallelism of the heavy DAG task. \\
        \hline
        \cite{Shi2024DagExecGroups}  & & & & \\
        \hline
        \cite{Guan2023FederatedNew}  & & & & \\
        \hline
        \cite{Zhao2024GATDRLmodel}  & & & & \\
        \hline
        \cite{Xu2023DRLtaskSched}  & & & & \\
        \hline
        \cite{Zhao2022DAGsched}  & & & & \\
        \hline
        \cite{Lee2021GlobalDagSchedDRL}  & & & & \\
        \hline
        \cite{Jiang2023SchedVirtualProcs}  & & & & \\
        \hline
        \cite{GuanFluidDag2022}  & & & & \\
        \hline
        \cite{GuanFRTDS2020RL}  & & & & \\
        \hline
        \cite{JiangVirtuallyFederatedSched2021}  & & & & \\
        \hline
        \cite{Pazzaglia2021DMALETtransfer} & & & & \\
        \hline
    \end{tabular}
    \caption{SLR summary table}
    \label{tab:slt_sum_table}
\end{table}


\subsubsection{DAG tasks}
~

Scheduling DAG tasks involves two steps: first, 
computing the intra-task schedule, and second, computing 
the inter-task schedule. For the inter-task schedule, various 
approaches can be employed.

\cite{WangGEDFDag2019}, for instance, improve the worst-case 
makespan of GEDF under federated scheduling of multiple DAG tasks 
with arbitrary deadlines. The federated scheduling approach, 
similar to the partitioning approach, involves assigning clusters 
of processors to DAG tasks with the highest utilization, leaving 
the remainder for low-utilization tasks. This allows for 
intra-task parallelization instead of merely sequentializing 
the DAG task. Consequently, the paper also improves the acceptance 
ratio for single DAG task scheduling by providing a better 
schedulability test compared to previously used 
schedulability tests for GEDF.

Another method is the decomposition approach, which involves 
decomposing the DAG task into several independent sequential tasks. 
These tasks are then executed in parallel segments, with their 
release times and deadlines aligned to match the dependency constraints 
between the sequential tasks\cite{CaoStretchingDAGs2020}. The paper 
\cite{CaoStretchingDAGs2020} introduces a state-of-the-art 
stretching method for DAG task decomposition and employs the GEDF 
dynamic priority assignment algorithm to demonstrate improvements 
in the acceptance ratio over the previous state-of-the-art 
decomposition algorithm.

\cite{SchmidResponseDAGThreadpools2021} explores a thread pool 
approach for parallelizing DAG tasks. Instead of assigning 
processors to DAG tasks, thread workers from a thread pool are 
assigned, and the number of thread workers each DAG can use is 
limited. Their algorithm, combined with a global fixed-point 
priority scheduling algorithm such as Rate Monotonic, is compared 
to other approaches, including the global approach and the 
semi-federated approach.

The global approach does not assign processors to DAG tasks but 
allows the tasks to utilize multiple processors dynamically. 
The semi-federated approach, similar to the federated approach, 
places as many heavy tasks (tasks with high utilization) in processor 
clusters as possible, while the remaining tasks, along with the 
light tasks, are allocated to the rest of the available processors.

It is found that the latest approach generally outperforms 
the method used in \cite{SchmidResponseDAGThreadpools2021}, although the 
thread pools approach still has a better acceptance ratio compared 
to the global approach.

The previously cited articles focus on the execution of multiple 
DAGs on a multi-processor system, utilizing existing priority 
scheduling algorithms such as GEDF or Global RM to evaluate their 
contributions. \cite{he2019intra} considers recurrent DAG tasks 
and their inner graph structure to develop a priority assignment 
algorithm that minimizes the makespan of the DAG task. This 
algorithm is then extended to multi-DAG scheduling using a global 
scheduling approach such as G-EDF or G-RM. This dynamic scheduling 
approach performs best with G-RM in terms of acceptance ratio.

The results in terms of acceptance ratio are superior to those in 
\cite{SchmidResponseDAGThreadpools2021}, though in some cases they 
are surpassed by \cite{CaoStretchingDAGs2020}. However, a 
drawback of \cite{CaoStretchingDAGs2020} is that this type of task 
decomposition incurs significant runtime overhead, which diminishes 
task performance in real-life scenarios.

While \cite{he2019intra} and \cite{CaoStretchingDAGs2020} allow 
for task preemption, which especially in the case of 
\cite{CaoStretchingDAGs2020} adds runtime overhead, 
\cite{zhao2020dag} leverages the parallelism and dependency 
properties of DAG tasks, along with a 'critical path first' 
execution strategy, to develop a state-of-the-art non-preemptive 
and priority-based scheduling algorithm that completely outperforms 
\cite{he2019intra} in terms of makespan. Their results are utilized 
by \cite{lee2021DAGDeeplearning} to compare with a deep 
learning-based priority assignment algorithm for DAGs, which 
improves the makespan of DAG task execution by 2$\sim$3\%.

\cite{zhao2022dag} extends their concurrent provider and consumer 
(CPC) model \cite{zhao2020dag} to multi-DAG scheduling by 
minimizing inter-task DAG interference to zero and devising a 
processor-assigning scheduling algorithm where the priority of 
different DAG tasks is computed using the deadline-monotonic 
algorithm. Under non-preemptive scheduling, the proposed method 
significantly outperforms the method used in \cite{he2019intra} in 
terms of acceptance ratio, by up to 60\%.

For multi-DAG scheduling, \cite{GuanDAGfluid2021} employed the 
fluid scheduling strategy to manage DAG tasks with implicit 
deadlines. This fluid scheduling approach, also used in PFair and 
LLREF scheduling algorithms \cite{baruah1993PFair}\cite{cho2006LLREF}, 
ensures that at every point in time, each task has utilized the 
amount of execution time dictated by its respective utilization 
factor, thereby approximating the perfect fluid execution of the 
task. The advantage of this approach is its exceptionally high 
acceptance ratio, outperforming other methods such as 
\cite{WangGEDFDag2019}, \cite{he2019intra}, and \cite{CaoStretchingDAGs2020}. 
However, it suffers from high runtime overhead, complicating 
practical implementation.
\newline

A more mathematical approach to the scheduling of DAGs is to model 
the scheduling problem as an Integer Linear Programming (ILP) 
optimization problem. In this model, precedence, deadline, and 
processor assignment constraints are represented mathematically, 
with the objective of minimizing the makespan. This method is 
utilized by \cite{ChangMinWRCTBoundILP2022} and compared to 
state-of-the-art priority assignment algorithms (\cite{he2019intra} 
and \cite{zhao2020dag}). The ILP method demonstrates a significant 
improvement in makespan, which is expected due to the optimality of 
the ILP approach. However, the drawback of this method is that as 
the number of tasks and subtasks increases, the number of 
constraints grows, causing the computation time to increase 
exponentially, rendering the method non-scalable.

Most studies do not consider the communication time between tasks, 
which can be significant in real-life systems. 
\cite{ChenDAGorder2023} addresses this by scheduling DAG tasks on a 
Network on Chip (NoC) system. The resulting schedule, DAG-Order, 
is non-preemptive and is based on ordering the tasks according to 
their communication delays and computation workloads.

Memory access contention, which occurs when two or more tasks 
attempt to access a shared memory location simultaneously, can 
also be crucial in real-life scenarios. Therefore, scheduling 
algorithms for implementations of the LET paradigm have been 
proposed to reduce or even eliminate contention problems with LET 
DAG tasks \cite{Yano2021ContentionFree}\cite{Igarashi2020HeuristicContFree}.
\newline


The machine learning community has also explored DAG scheduling. 
For instance, \cite{yano2021work} utilized reinforcement 
learning (RL), specifically Q-learning, to statically prioritize 
sub-tasks within DAG tasks and applied an 
earliest-start-first (EST) heuristic value to dispatch each 
sub-task to different processors. Similar to \cite{ChenDAGorder2023}, 
\cite{yano2021work} accounted for communication delays and the 
workload of subtasks when assigning priorities.

Another application of RL is demonstrated by 
\cite{lee2021DAGDeeplearning}, who designed a deep learning model 
based on RL that uses the spatial features of each DAG task as well 
as their temporal features, i.e., precedence constraints. They 
achieved this by combining a graph convolution network 
(for spatial information) with a sequential encoder 
(for temporal information), ultimately producing a prioritized list 
of the DAG's subtasks. This list can then be used to compute 
the makespan and optimize it via RL. The results in 
\cite{lee2021DAGDeeplearning} were compared with state-of-the-art (SOTA) 
algorithms \cite{he2019intra}\cite{zhao2020dag}, with the deep 
reinforcement learning method surpassing the SOTA by up to 3\% 
in terms of makespan.

\input{slrtable}

As you can see, although dynamic priority algorithms outperform 
fixed-priority ones, the simplicity of implementation and low runtime 
overhead of fixed-priority algorithms make them attractive to the 
industry. This is especially true for the DAG task model, where 
there has been significant focus on fixed-priority scheduling. While 
some have attempted to produce an 'optimal' schedule using 
ILP\cite{wei2011reliabilityILP}\cite{yip2014relaxing}\cite{ChangMinWRCTBoundILP2022}, 
the primary issue with this method is its lack of scalability.

Regarding task migrations, the NP-hard nature of the 
bin-packing problem suggests that allowing tasks or subtasks to migrate 
between processors can improve utilization performance.


Also, only 3 articles used machine learning to tackle the task scheduling problem,
from which two are from the same author.
Furthermore, those articles only compare their results to 
heuristic-based methods and not ILP methods.
If we focus on DAG tasks, then only 2 papers are left,
one focusing on communication between the cores and
applying the model on a specific architecture\cite{yano2021work},
and one more theoretical\cite{lee2021DAGDeeplearning}, comparing their model to SOTA 
\cite{zhao2020dag} and \cite{he2019intra}. The latter suffers 
from closed sourcing as their model is not open source
which prohibits the research community to improve on their work. 

Hence, there not only is a need to compare one such machine learning technique 
to the non-scalable but leading to the mathematically minimum makespan, ILP method,
but there also is a need to have this model open source and open access.
Therefore, in this paper, an attempt at replicating the model described
in \cite{lee2021DAGDeeplearning} will be done and 
a comparison with the SOTA heuristic-based algorithms
and ILP will be conducted using the open-source software 
for LET task scheduling LETSyncronize\cite{yip2023letsynchronise}.
