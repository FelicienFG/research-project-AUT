
\section{Related Works}
\label{sec:literature}

\subsection{Systematic Literature Review process}

\paraheading{\textbf{Scoping}}

This SLR aims at tackling RQ1. More precisely, the following research questions will be answered:

\begin{itemize}
    \item [RQ1.1] What is the current state-of-the-Art for DAG task scheduling with precedence constraints ?
    \item [RQ1.2] How has LET been used in scheduling event-chains ?
    \item [RQ1.3] What machine learning techniques have been used for scheduling tasks on real-time systems ?
\end{itemize}
It will also be shown how the literature doesn't provide 
a complete answer to RQ2, hence the contributions of this paper.\\

From these research questions, several concepts have been isolated,
namely, time-triggered tasks, the nature of the system (real-time multicore system),
the scheduling of tasks, DAG tasks, and machine learning.
The recording of the search results were done using the BibTeX LateX plugin
combine with the google scholar "cite" feature.

Searching was conducted using the IEEE and ACM databases.
According to the concepts identified above, 
the keyword chain used for searching was 
"("real-time" OR "real time") AND 
"system" AND ("time-triggered" OR "time triggered" OR "DAG" OR "Directed Acyclic Graph" OR "LET" OR "Logical Execution Time" OR "event chain" OR "event-chain") 
AND "task" 
AND ("scheduling" OR "scheduler" OR "schedule") 
AND ("multi-processors" OR "multi-cores" OR "multi processors" OR 
"multi cores" OR "multi-processor" OR "multi processor" OR 
"multi-core" OR "multi core")".

The search produced 3,549 results on the IEEE database

exclusion : past 5 years : IEEE --> down to 1,171 
            heterogeneous not in title + abstract : IEEE --> down to 999
            mixed critical* not in title + abstract : IEEE --> down to 952
            scheduling or scheduler or schedule in title but not "energy" :  IEEE --> down to 155 and 149 when just considering conference and journal papers (not early access)
            
            removing those not about real-time system,
            not about proposing a scheduling algorithm,
            not about DAG nor LET tasks or event-chains : IEEE --> down to 21
            After reading the complete articles --> 19.

\paragraph{}

\subsection{Findings of the Literature Review}

\paraheading{The works reviewed were compared on the following metrics.} 
\begin{itemize}
    \item \textbf{Utilization Bound}: useful to see which algorithm is more efficient at using the available resources.
    \item \textbf{Acceptance Ratio}: it shows how optimal (see Section \ref{sec:bg}) a scheduling algorithm is.
    \item \textbf{Makespan}: for DAG task scheduling, widely used in the literature.
    \item \textbf{Runtime Overhead}: some scheduling algorithms can show promising results theoretically but are practically very slow because 
    of their complexity adding runtime overhead on the scheduler, this metric will not be a number but rather an amount such as minimal, practical, non-practical.
\end{itemize}
Every metric used here have also been chosen for their prevalence in the literature.

A comparison of the works was carried out and the overall results are illustrated in Table~\ref{tab:slrtable}.
 

\begin{table}
    \centering
    \begin{tabular}[]{|l|p{0.20\linewidth}|p{0.20\linewidth}|p{0.20\linewidth}|}
        \hline
        \textbf{Reference} & \textbf{Scheduling technique} & \textbf{Task type} & \textbf{Scope (intra/inter/both)}\\
        \hline
        \cite{guan2021DAGfluid} & fluid & implicit deadline & inter\\
        \hline
        \cite{He2019DagIntra} & priority-list & constrained deadline & intra \\
        \hline
        \cite{Kobayashi2023FedBundledDagsched} & federated and bundled-based & constrained deadline & inter\\
        \hline
        \cite{Xiao2019}  & clustering & constrained deadline & intra\\ 
        \hline
        \cite{Igarashi2020HeuristicContentionFree}  & priority-list & LET constrained deadline & both \\
        \hline
        \cite{jiangUtilTensityBound}  & federated and GEDF and PEDF & implicit deadline & inter\\
        \hline
        \cite{JiangDecompoSchedParallelTask} & Decomposition-based & implicit deadline & inter \\
        \hline
        \cite{He2023DegreeOfParallelism} & federated-based & constrained deadlines & inter \\
        \hline
        \cite{Shi2024DagExecGroups}  & partitioned / clustering & constrained deadlines & intra\\
        \hline
        \cite{Guan2023FederatedNew}  & federated & arbitrary deadline & inter\\
        \hline
        \cite{Zhao2024GATDRLmodel} & DRL & constrained deadline & intra\\
        \hline
        \cite{Xu2023DRLtaskSched} & DRL & non-DAG implicit deadline & inter\\
        \hline
        \cite{Zhao2022DAGsched} & priority-list and federated & constrained deadline & both \\
        \hline
        \cite{Lee2021GlobalDagSchedDRL} & DRL & constrained deadline & intra\\
        \hline
        \cite{Jiang2023SchedVirtualProcs} & federated-based & constrained deadline & inter\\
        \hline
        \cite{GuanFluidDag2022} & fluid & constrained/arbitrary deadline & inter\\
        \hline
        \cite{GuanFRTDS2020RL} & DRL & constrained deadline & intra \\
        \hline
        \cite{JiangVirtuallyFederatedSched2021} & federated-based & constrained deadline & inter\\
        \hline
        \cite{Pazzaglia2021DMALETtransfer} & Mixed ILP & LET, constrained deadline & inter\\
        \hline
        \textbf{Total: 19} & \textbf{DRL: 4, Federated: 7, Fluid: 2, ILP: 1, Priority-List(intra): 3, Clustering: 2, Decomposition: 1}
        & \textbf{implicit: 4, constrained: 13, arbitrary: 2} & \textbf{inter: 11, intra: 6, both: 2} \\
        \hline
    \end{tabular}
    \caption{SLR summary table}
    \label{tab:slt_sum_table}
\end{table}


\subsubsection{DAG tasks}
~

Scheduling DAG tasks involves two steps: first, 
computing the intra-task schedule, and second, computing 
the inter-task schedule. For the inter-task schedule, various 
approaches can be employed.

\cite{WangGEDFDag2019}, for instance, improve the worst-case 
makespan of GEDF under federated scheduling of multiple DAG tasks 
with arbitrary deadlines. The federated scheduling approach, 
similar to the partitioning approach, involves assigning clusters 
of processors to DAG tasks with the highest utilization, leaving 
the remainder for low-utilization tasks. This allows for 
intra-task parallelization instead of merely sequentializing 
the DAG task. Consequently, the paper also improves the acceptance 
ratio for single DAG task scheduling by providing a better 
schedulability test compared to previously used 
schedulability tests for GEDF.

Another method is the decomposition approach, which involves 
decomposing the DAG task into several independent sequential tasks. 
These tasks are then executed in parallel segments, with their 
release times and deadlines aligned to match the dependency constraints 
between the sequential tasks\cite{CaoStretchingDAGs2020}. The paper 
\cite{CaoStretchingDAGs2020} introduces a state-of-the-art 
stretching method for DAG task decomposition and employs the GEDF 
dynamic priority assignment algorithm to demonstrate improvements 
in the acceptance ratio over the previous state-of-the-art 
decomposition algorithm.

\cite{SchmidResponseDAGThreadpools2021} explores a thread pool 
approach for parallelizing DAG tasks. Instead of assigning 
processors to DAG tasks, thread workers from a thread pool are 
assigned, and the number of thread workers each DAG can use is 
limited. Their algorithm, combined with a global fixed-point 
priority scheduling algorithm such as Rate Monotonic, is compared 
to other approaches, including the global approach and the 
semi-federated approach.

The global approach does not assign processors to DAG tasks but 
allows the tasks to utilize multiple processors dynamically. 
The semi-federated approach, similar to the federated approach, 
places as many heavy tasks (tasks with high utilization) in processor 
clusters as possible, while the remaining tasks, along with the 
light tasks, are allocated to the rest of the available processors.

It is found that the latest approach generally outperforms 
the method used in \cite{SchmidResponseDAGThreadpools2021}, although the 
thread pools approach still has a better acceptance ratio compared 
to the global approach.

The previously cited articles focus on the execution of multiple 
DAGs on a multi-processor system, utilizing existing priority 
scheduling algorithms such as GEDF or Global RM to evaluate their 
contributions. \cite{he2019intra} considers recurrent DAG tasks 
and their inner graph structure to develop a priority assignment 
algorithm that minimizes the makespan of the DAG task. This 
algorithm is then extended to multi-DAG scheduling using a global 
scheduling approach such as G-EDF or G-RM. This dynamic scheduling 
approach performs best with G-RM in terms of acceptance ratio.

The results in terms of acceptance ratio are superior to those in 
\cite{SchmidResponseDAGThreadpools2021}, though in some cases they 
are surpassed by \cite{CaoStretchingDAGs2020}. However, a 
drawback of \cite{CaoStretchingDAGs2020} is that this type of task 
decomposition incurs significant runtime overhead, which diminishes 
task performance in real-life scenarios.

While \cite{he2019intra} and \cite{CaoStretchingDAGs2020} allow 
for task preemption, which especially in the case of 
\cite{CaoStretchingDAGs2020} adds runtime overhead, 
\cite{zhao2020dag} leverages the parallelism and dependency 
properties of DAG tasks, along with a 'critical path first' 
execution strategy, to develop a state-of-the-art non-preemptive 
and priority-based scheduling algorithm that completely outperforms 
\cite{he2019intra} in terms of makespan. Their results are utilized 
by \cite{lee2021DAGDeeplearning} to compare with a deep 
learning-based priority assignment algorithm for DAGs, which 
improves the makespan of DAG task execution by 2$\sim$3\%.

\cite{zhao2022dag} extends their concurrent provider and consumer 
(CPC) model \cite{zhao2020dag} to multi-DAG scheduling by 
minimizing inter-task DAG interference to zero and devising a 
processor-assigning scheduling algorithm where the priority of 
different DAG tasks is computed using the deadline-monotonic 
algorithm. Under non-preemptive scheduling, the proposed method 
significantly outperforms the method used in \cite{he2019intra} in 
terms of acceptance ratio, by up to 60\%.

For multi-DAG scheduling, \cite{GuanDAGfluid2021} employed the 
fluid scheduling strategy to manage DAG tasks with implicit 
deadlines. This fluid scheduling approach, also used in PFair and 
LLREF scheduling algorithms \cite{baruah1993PFair}\cite{cho2006LLREF}, 
ensures that at every point in time, each task has utilized the 
amount of execution time dictated by its respective utilization 
factor, thereby approximating the perfect fluid execution of the 
task. The advantage of this approach is its exceptionally high 
acceptance ratio, outperforming other methods such as 
\cite{WangGEDFDag2019}, \cite{he2019intra}, and \cite{CaoStretchingDAGs2020}. 
However, it suffers from high runtime overhead, complicating 
practical implementation.
\newline

A more mathematical approach to the scheduling of DAGs is to model 
the scheduling problem as an Integer Linear Programming (ILP) 
optimization problem. In this model, precedence, deadline, and 
processor assignment constraints are represented mathematically, 
with the objective of minimizing the makespan. This method is 
utilized by \cite{ChangMinWRCTBoundILP2022} and compared to 
state-of-the-art priority assignment algorithms (\cite{he2019intra} 
and \cite{zhao2020dag}). The ILP method demonstrates a significant 
improvement in makespan, which is expected due to the optimality of 
the ILP approach. However, the drawback of this method is that as 
the number of tasks and subtasks increases, the number of 
constraints grows, causing the computation time to increase 
exponentially, rendering the method non-scalable.

Most studies do not consider the communication time between tasks, 
which can be significant in real-life systems. 
\cite{ChenDAGorder2023} addresses this by scheduling DAG tasks on a 
Network on Chip (NoC) system. The resulting schedule, DAG-Order, 
is non-preemptive and is based on ordering the tasks according to 
their communication delays and computation workloads.

Memory access contention, which occurs when two or more tasks 
attempt to access a shared memory location simultaneously, can 
also be crucial in real-life scenarios. Therefore, scheduling 
algorithms for implementations of the LET paradigm have been 
proposed to reduce or even eliminate contention problems with LET 
DAG tasks \cite{Yano2021ContentionFree}\cite{Igarashi2020HeuristicContFree}.
\newline


The machine learning community has also explored DAG scheduling. 
For instance, \cite{yano2021work} utilized reinforcement 
learning (RL), specifically Q-learning, to statically prioritize 
sub-tasks within DAG tasks and applied an 
earliest-start-first (EST) heuristic value to dispatch each 
sub-task to different processors. Similar to \cite{ChenDAGorder2023}, 
\cite{yano2021work} accounted for communication delays and the 
workload of subtasks when assigning priorities.

Another application of RL is demonstrated by 
\cite{lee2021DAGDeeplearning}, who designed a deep learning model 
based on RL that uses the spatial features of each DAG task as well 
as their temporal features, i.e., precedence constraints. They 
achieved this by combining a graph convolution network 
(for spatial information) with a sequential encoder 
(for temporal information), ultimately producing a prioritized list 
of the DAG's subtasks. This list can then be used to compute 
the makespan and optimize it via RL. The results in 
\cite{lee2021DAGDeeplearning} were compared with state-of-the-art (SOTA) 
algorithms \cite{he2019intra}\cite{zhao2020dag}, with the deep 
reinforcement learning method surpassing the SOTA by up to 3\% 
in terms of makespan.

\input{slrtable}

As you can see, although dynamic priority algorithms outperform 
fixed-priority ones, the simplicity of implementation and low runtime 
overhead of fixed-priority algorithms make them attractive to the 
industry. This is especially true for the DAG task model, where 
there has been significant focus on fixed-priority scheduling. While 
some have attempted to produce an 'optimal' schedule using 
ILP\cite{wei2011reliabilityILP}\cite{yip2014relaxing}\cite{ChangMinWRCTBoundILP2022}, 
the primary issue with this method is its lack of scalability.

Regarding task migrations, the NP-hard nature of the 
bin-packing problem suggests that allowing tasks or subtasks to migrate 
between processors can improve utilization performance.


Also, only 3 articles used machine learning to tackle the task scheduling problem,
from which two are from the same author.
Furthermore, those articles only compare their results to 
heuristic-based methods and not ILP methods.
If we focus on DAG tasks, then only 2 papers are left,
one focusing on communication between the cores and
applying the model on a specific architecture\cite{yano2021work},
and one more theoretical\cite{lee2021DAGDeeplearning}, comparing their model to SOTA 
\cite{zhao2020dag} and \cite{he2019intra}. The latter suffers 
from closed sourcing as their model is not open source
which prohibits the research community to improve on their work. 

Hence, there not only is a need to compare one such machine learning technique 
to the non-scalable but leading to the mathematically minimum makespan, ILP method,
but there also is a need to have this model open source and open access.
Therefore, in this paper, an attempt at replicating the model described
in \cite{lee2021DAGDeeplearning} will be done and 
a comparison with the SOTA heuristic-based algorithms
and ILP will be conducted using the open-source software 
for LET task scheduling LETSyncronize\cite{yip2023letsynchronise}.
